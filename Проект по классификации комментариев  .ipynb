{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Библиотеки\" data-toc-modified-id=\"Библиотеки-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Библиотеки</a></span></li><li><span><a href=\"#Получение-данных\" data-toc-modified-id=\"Получение-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Получение данных</a></span></li><li><span><a href=\"#Лишние-данные\" data-toc-modified-id=\"Лишние-данные-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Лишние данные</a></span></li><li><span><a href=\"#Лемматизация\" data-toc-modified-id=\"Лемматизация-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Лемматизация</a></span></li><li><span><a href=\"#Разделение-на-выборки\" data-toc-modified-id=\"Разделение-на-выборки-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Разделение на выборки</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Тестирование</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект по классификации комментариев  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить модель классифицировать комментарии на позитивные и негативные. В  распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построить модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: catBoost in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.9.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (3.5.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (5.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catBoost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catBoost) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (4.25.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from plotly->catBoost) (8.0.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (1.1.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "     -------------------------------------- 13.6/13.6 MB 903.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.23.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.64.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.17)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (63.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.28.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2022.9.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install catBoost\n",
    "!pip install lightgbm\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sheyk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sheyk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Узнаем размер данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лишние данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть неинформативный столбец `Unnamed: 0`, удалим его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в столбце `text` есть объекты с русскими символами, то удалим их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_russian(x):\n",
    "    if bool(re.search('[а-яА-ЯёЁ]', x)):\n",
    "        return 'russian'\n",
    "    else:\n",
    "        return (' '.join(re.sub(r'[^a-zA-Z]', ' ', x).split())).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(checking_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'] == 'russian'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'] != 'russian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "- Удалено 259 объектов, в которых фигурировались русские символы.\n",
    "- Удалили все знаки препинания, удали оставили только английские символы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения моделей нужно лемматизировать наши данные - привести слова в тексте в начальный вид и к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "disabled_pipes = [ \"parser\",  \"ner\"]\n",
    "nlp = spacy.load('en_core_web_sm', disable=disabled_pipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"lemmatized_text\"] = df[\"text\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edit make under my username hardcore metallica fan be revert they weren t vandalism just closure on some gas after I vote at new york doll fac and please don t remove the template from the talk page since I m retire now'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'lemmatized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Лемматизация прошла успешно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим наши данные на 3 выборки: \n",
    "\n",
    "- Обучающая выборка: 75%\n",
    "- Валидационная выборка: 12.5%\n",
    "- Тестовая выборка: 12.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, random_state=RANDOM_STATE, test_size=0.25)\n",
    "valid_df, test_df = train_test_split(temp_df, random_state=RANDOM_STATE, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_df['lemmatized_text'] \n",
    "target_train = train_df['toxic']\n",
    "\n",
    "features_valid = valid_df['lemmatized_text'] \n",
    "target_valid = valid_df['toxic']\n",
    "\n",
    "features_test = test_df[['lemmatized_text'] ]\n",
    "target_test = test_df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Успешно разделили наши данные на выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первой моделью будет CatBoost, а именно версия CatBoostClassifier, в данной модели есть такой параметр при обучении как text_features, который позволяет обрабатывать текстовую информацию без внешних преобразований."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6851816\ttest: 0.6964892\tbest: 0.6964892 (0)\ttotal: 262ms\tremaining: 4m 21s\n",
      "100:\tlearn: 0.8273729\ttest: 0.7727992\tbest: 0.7749273 (69)\ttotal: 7.39s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.8578275\ttest: 0.7730384\tbest: 0.7749273 (69)\ttotal: 14.3s\tremaining: 57s\n",
      "300:\tlearn: 0.8788812\ttest: 0.7764335\tbest: 0.7775151 (276)\ttotal: 21.4s\tremaining: 49.7s\n",
      "400:\tlearn: 0.8962474\ttest: 0.7789142\tbest: 0.7795544 (384)\ttotal: 28.5s\tremaining: 42.6s\n",
      "500:\tlearn: 0.9101333\ttest: 0.7793501\tbest: 0.7800786 (495)\ttotal: 35.5s\tremaining: 35.4s\n",
      "600:\tlearn: 0.9225194\ttest: 0.7836349\tbest: 0.7841387 (588)\ttotal: 42.4s\tremaining: 28.2s\n",
      "700:\tlearn: 0.9327958\ttest: 0.7816754\tbest: 0.7841802 (607)\ttotal: 49.6s\tremaining: 21.2s\n",
      "800:\tlearn: 0.9410560\ttest: 0.7853595\tbest: 0.7854716 (795)\ttotal: 56.6s\tremaining: 14.1s\n",
      "900:\tlearn: 0.9480801\ttest: 0.7866284\tbest: 0.7875621 (899)\ttotal: 1m 3s\tremaining: 7s\n",
      "999:\tlearn: 0.9549496\ttest: 0.7860125\tbest: 0.7875621 (899)\ttotal: 1m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7875620591\n",
      "bestIteration = 899\n",
      "\n",
      "Shrink model to first 900 iterations.\n",
      "Wall time: 1min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x274840a9d60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_catboost = CatBoostClassifier(verbose=100, learning_rate=0.7, early_stopping_rounds=200, eval_metric=\"F1\")\n",
    "model_catboost.fit(train_df[['lemmatized_text']], train_df[['toxic']], eval_set=(valid_df[['lemmatized_text']], valid_df[['toxic']]), text_features=['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Модель CatBoostClassifier была обучена, получили следующие результаты:\n",
    "\n",
    "-  Время обучения: 1min 24s\n",
    "-  Метрика F1: 0.7737306843267109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй будем использовать модель LogisticRegression, для её обучения будем использовать метод TF-IDF для работы с текстом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_regression = Pipeline(\n",
    "    [('tf', TfidfVectorizer(stop_words=stopwords, ngram_range=(1, 1))), \n",
    "     ('reg', LogisticRegression(random_state=RANDOM_STATE, class_weight='balanced', solver='liblinear', max_iter=1000, verbose=1, C=1.0))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Wall time: 6.01 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;reg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=12345, solver=&#x27;liblinear&#x27;,\n",
       "                                    verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;reg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=12345, solver=&#x27;liblinear&#x27;,\n",
       "                                    verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=12345,\n",
       "                   solver=&#x27;liblinear&#x27;, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('reg',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000,\n",
       "                                    random_state=12345, solver='liblinear',\n",
       "                                    verbose=1))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_regression.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_regression = model_regression.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7549584133077414"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_score(pred_regression, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Модель LogisticRegression была обучена, получили следующие результаты:\n",
    "\n",
    "-  Время обучения: 8.19 s\n",
    "-  Метрика F1: 0.7549584133077414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_catboost = model_catboost.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7737306843267109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_score(predict_catboost, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат метрики F1 выше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Были удалены объекты с русскими символами.\n",
    "- Данные были лемматизированы.\n",
    "- Лучшая модель CatBoostClassifier с результатами:  \n",
    " -  Время обучения: 1min 24s\n",
    " -   Метрика F1 на тестовой выборке: 0.7737306843267109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 112,
    "start_time": "2023-05-03T16:21:21.494Z"
   },
   {
    "duration": 14259,
    "start_time": "2023-05-03T16:22:04.434Z"
   },
   {
    "duration": 3786,
    "start_time": "2023-05-03T16:22:18.695Z"
   },
   {
    "duration": 282,
    "start_time": "2023-05-03T16:22:22.483Z"
   },
   {
    "duration": 350,
    "start_time": "2023-05-03T16:22:22.767Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.120Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.121Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.122Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.134Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.135Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.136Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.138Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.139Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.140Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.141Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.142Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.143Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.145Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.146Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.147Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.148Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.149Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.150Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.151Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.152Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.154Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.155Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.155Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
