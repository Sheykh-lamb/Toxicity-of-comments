{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞\" data-toc-modified-id=\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞</a></span><ul class=\"toc-item\"><li><span><a href=\"#–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏\" data-toc-modified-id=\"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>–ë–∏–±–ª–∏–æ—Ç–µ–∫–∏</a></span></li><li><span><a href=\"#–ü–æ–ª—É—á–µ–Ω–∏–µ-–¥–∞–Ω–Ω—ã—Ö\" data-toc-modified-id=\"–ü–æ–ª—É—á–µ–Ω–∏–µ-–¥–∞–Ω–Ω—ã—Ö-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö</a></span></li><li><span><a href=\"#–õ–∏—à–Ω–∏–µ-–¥–∞–Ω–Ω—ã–µ\" data-toc-modified-id=\"–õ–∏—à–Ω–∏–µ-–¥–∞–Ω–Ω—ã–µ-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>–õ–∏—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ</a></span></li><li><span><a href=\"#–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\" data-toc-modified-id=\"–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è</a></span></li><li><span><a href=\"#–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ-–Ω–∞-–≤—ã–±–æ—Ä–∫–∏\" data-toc-modified-id=\"–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ-–Ω–∞-–≤—ã–±–æ—Ä–∫–∏-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏</a></span></li></ul></li><li><span><a href=\"#–û–±—É—á–µ–Ω–∏–µ\" data-toc-modified-id=\"–û–±—É—á–µ–Ω–∏–µ-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>–û–±—É—á–µ–Ω–∏–µ</a></span><ul class=\"toc-item\"><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ\" data-toc-modified-id=\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ</a></span></li></ul></li><li><span><a href=\"#–í—ã–≤–æ–¥—ã\" data-toc-modified-id=\"–í—ã–≤–æ–¥—ã-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>–í—ã–≤–æ–¥—ã</a></span></li><li><span><a href=\"#–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏\" data-toc-modified-id=\"–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>–ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. –í  —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫.\n",
    "\n",
    "–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: catBoost in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.9.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (3.5.2)\n",
      "Requirement already satisfied: graphviz in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from catBoost) (5.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catBoost) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catBoost) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from matplotlib->catBoost) (4.25.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from plotly->catBoost) (8.0.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (1.1.3)\n",
      "Requirement already satisfied: wheel in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "     -------------------------------------- 13.6/13.6 MB 903.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.23.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.64.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.17)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.10.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (63.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.28.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2022.9.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sheyk\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install catBoost\n",
    "!pip install lightgbm\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from catboost import CatBoostClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sheyk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sheyk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>159446</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>159447</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>159448</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>159449</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>159450</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "0                0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1                1  D'aww! He matches this background colour I'm s...      0\n",
       "2                2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3                3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4                4  You, sir, are my hero. Any chance you remember...      0\n",
       "...            ...                                                ...    ...\n",
       "159287      159446  \":::::And for the second time of asking, when ...      0\n",
       "159288      159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159289      159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159290      159449  And it looks like it was actually you who put ...      0\n",
       "159291      159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–∑–Ω–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞: </b></font> ‚úîÔ∏è\\\n",
    "<font color='green'>–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ, –ø–µ—Ä–≤–∏—á–Ω—ã–π –æ—Å–º–æ—Ç—Ä –ø—Ä–æ–≤–µ–¥–µ–Ω.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –õ–∏—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –¥–∞–Ω–Ω—ã—Ö –µ—Å—Ç—å –Ω–µ–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü `Unnamed: 0`, —É–¥–∞–ª–∏–º –µ–≥–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –≤ —Å—Ç–æ–ª–±—Ü–µ `text` –µ—Å—Ç—å –æ–±—ä–µ–∫—Ç—ã —Å —Ä—É—Å—Å–∫–∏–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏, —Ç–æ —É–¥–∞–ª–∏–º –∏—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checking_russian(x):\n",
    "    if bool(re.search('[–∞-—è–ê-–Ø—ë–Å]', x)):\n",
    "        return 'russian'\n",
    "    else:\n",
    "        return (' '.join(re.sub(r'[^a-zA-Z]', ' ', x).split())).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(checking_russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(259, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'] == 'russian'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['text'] != 'russian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥**\n",
    "\n",
    "- –£–¥–∞–ª–µ–Ω–æ 259 –æ–±—ä–µ–∫—Ç–æ–≤, –≤ –∫–æ—Ç–æ—Ä—ã—Ö —Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–ª–∏—Å—å —Ä—É—Å—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã.\n",
    "- –£–¥–∞–ª–∏–ª–∏ –≤—Å–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, —É–¥–∞–ª–∏ –æ—Å—Ç–∞–≤–∏–ª–∏ —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–∏–º–≤–æ–ª—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞ 2: </b></font> ‚úîÔ∏è\\\n",
    "<font color='green'> üëç</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω—É–∂–Ω–æ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ - –ø—Ä–∏–≤–µ—Å—Ç–∏ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ –≤ –Ω–∞—á–∞–ª—å–Ω—ã–π –≤–∏–¥ –∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "disabled_pipes = [ \"parser\",  \"ner\"]\n",
    "nlp = spacy.load('en_core_web_sm', disable=disabled_pipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'><b>–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Ä–µ–≤—å—é–µ—Ä–∞: </b></font> ‚úîÔ∏è\\\n",
    "<font color='green'> –•–æ—Ä–æ—à–∏–π –≤—ã–±–æ—Ä –õ–µ–º–º–∞—Ç–∞–π–∑–µ—Ä–∞! –ü—Ä–æ –¥—Ä—É–≥–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å [—Ç—É—Ç](https://webdevblog.ru/podhody-lemmatizacii-s-primerami-v-python/)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"lemmatized_text\"] = df[\"text\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edit make under my username hardcore metallica fan be revert they weren t vandalism just closure on some gas after I vote at new york doll fac and please don t remove the template from the talk page since I m retire now'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'lemmatized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they weren t vandalisms just closure on some gas after i voted at new york dolls fac and please don t remove the template from the talk page since i m retired now'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥**\n",
    "\n",
    "–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–¥–µ–ª–∏–º –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ 3 –≤—ã–±–æ—Ä–∫–∏: \n",
    "\n",
    "- –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: 75%\n",
    "- –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: 12.5%\n",
    "- –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: 12.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, random_state=RANDOM_STATE, test_size=0.25)\n",
    "valid_df, test_df = train_test_split(temp_df, random_state=RANDOM_STATE, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_df['lemmatized_text'] \n",
    "target_train = train_df['toxic']\n",
    "\n",
    "features_valid = valid_df['lemmatized_text'] \n",
    "target_valid = valid_df['toxic']\n",
    "\n",
    "features_test = test_df[['lemmatized_text'] ]\n",
    "target_test = test_df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥**\n",
    "\n",
    "–£—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–∏–ª–∏ –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–≤–æ–π –º–æ–¥–µ–ª—å—é –±—É–¥–µ—Ç CatBoost, –∞ –∏–º–µ–Ω–Ω–æ –≤–µ—Ä—Å–∏—è CatBoostClassifier, –≤ –¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å —Ç–∞–∫–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –∫–∞–∫ text_features, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6851816\ttest: 0.6964892\tbest: 0.6964892 (0)\ttotal: 262ms\tremaining: 4m 21s\n",
      "100:\tlearn: 0.8273729\ttest: 0.7727992\tbest: 0.7749273 (69)\ttotal: 7.39s\tremaining: 1m 5s\n",
      "200:\tlearn: 0.8578275\ttest: 0.7730384\tbest: 0.7749273 (69)\ttotal: 14.3s\tremaining: 57s\n",
      "300:\tlearn: 0.8788812\ttest: 0.7764335\tbest: 0.7775151 (276)\ttotal: 21.4s\tremaining: 49.7s\n",
      "400:\tlearn: 0.8962474\ttest: 0.7789142\tbest: 0.7795544 (384)\ttotal: 28.5s\tremaining: 42.6s\n",
      "500:\tlearn: 0.9101333\ttest: 0.7793501\tbest: 0.7800786 (495)\ttotal: 35.5s\tremaining: 35.4s\n",
      "600:\tlearn: 0.9225194\ttest: 0.7836349\tbest: 0.7841387 (588)\ttotal: 42.4s\tremaining: 28.2s\n",
      "700:\tlearn: 0.9327958\ttest: 0.7816754\tbest: 0.7841802 (607)\ttotal: 49.6s\tremaining: 21.2s\n",
      "800:\tlearn: 0.9410560\ttest: 0.7853595\tbest: 0.7854716 (795)\ttotal: 56.6s\tremaining: 14.1s\n",
      "900:\tlearn: 0.9480801\ttest: 0.7866284\tbest: 0.7875621 (899)\ttotal: 1m 3s\tremaining: 7s\n",
      "999:\tlearn: 0.9549496\ttest: 0.7860125\tbest: 0.7875621 (899)\ttotal: 1m 10s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7875620591\n",
      "bestIteration = 899\n",
      "\n",
      "Shrink model to first 900 iterations.\n",
      "Wall time: 1min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x274840a9d60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_catboost = CatBoostClassifier(verbose=100, learning_rate=0.7, early_stopping_rounds=200, eval_metric=\"F1\")\n",
    "model_catboost.fit(train_df[['lemmatized_text']], train_df[['toxic']], eval_set=(valid_df[['lemmatized_text']], valid_df[['toxic']]), text_features=['lemmatized_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥**\n",
    "\n",
    "–ú–æ–¥–µ–ª—å CatBoostClassifier –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞, –ø–æ–ª—É—á–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n",
    "\n",
    "-  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 1min 24s\n",
    "-  –ú–µ—Ç—Ä–∏–∫–∞ F1: 0.7737306843267109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Ç–æ—Ä–æ–π –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å LogisticRegression, –¥–ª—è –µ—ë –æ–±—É—á–µ–Ω–∏—è –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ TF-IDF –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–∫—Å—Ç–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_regression = Pipeline(\n",
    "    [('tf', TfidfVectorizer(stop_words=stopwords, ngram_range=(1, 1))), \n",
    "     ('reg', LogisticRegression(random_state=RANDOM_STATE, class_weight='balanced', solver='liblinear', max_iter=1000, verbose=1, C=1.0))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Wall time: 6.01 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;reg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=12345, solver=&#x27;liblinear&#x27;,\n",
       "                                    verbose=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;reg&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
       "                                    random_state=12345, solver=&#x27;liblinear&#x27;,\n",
       "                                    verbose=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=12345,\n",
       "                   solver=&#x27;liblinear&#x27;, verbose=1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tf',\n",
       "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
       "                                             'again', 'against', 'ain', 'all',\n",
       "                                             'am', 'an', 'and', 'any', 'are',\n",
       "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
       "                                             'because', 'been', 'before',\n",
       "                                             'being', 'below', 'between',\n",
       "                                             'both', 'but', 'by', 'can',\n",
       "                                             'couldn', \"couldn't\", ...})),\n",
       "                ('reg',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000,\n",
       "                                    random_state=12345, solver='liblinear',\n",
       "                                    verbose=1))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_regression.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_regression = model_regression.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7549584133077414"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_score(pred_regression, target_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥**\n",
    "\n",
    "–ú–æ–¥–µ–ª—å LogisticRegression –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞, –ø–æ–ª—É—á–∏–ª–∏ —Å–ª–µ–¥—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n",
    "\n",
    "-  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 8.19 s\n",
    "-  –ú–µ—Ç—Ä–∏–∫–∞ F1: 0.7549584133077414"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_catboost = model_catboost.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7737306843267109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f1_score(predict_catboost, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –º–µ—Ç—Ä–∏–∫–∏ F1 –≤—ã—à–µ 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –ë—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã –æ–±—ä–µ–∫—Ç—ã —Å —Ä—É—Å—Å–∫–∏–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏.\n",
    "- –î–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –ª–µ–º–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.\n",
    "- –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å CatBoostClassifier —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:  \n",
    " -  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 1min 24s\n",
    " -   –ú–µ—Ç—Ä–∏–∫–∞ F1 –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: 0.7737306843267109"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook –æ—Ç–∫—Ä—ã—Ç\n",
    "- [x]  –í–µ—Å—å –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫\n",
    "- [x]  –Ø—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "- [x]  –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã\n",
    "- [x]  –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã\n",
    "- [x]  –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75\n",
    "- [x]  –í—ã–≤–æ–¥—ã –Ω–∞–ø–∏—Å–∞–Ω—ã"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 112,
    "start_time": "2023-05-03T16:21:21.494Z"
   },
   {
    "duration": 14259,
    "start_time": "2023-05-03T16:22:04.434Z"
   },
   {
    "duration": 3786,
    "start_time": "2023-05-03T16:22:18.695Z"
   },
   {
    "duration": 282,
    "start_time": "2023-05-03T16:22:22.483Z"
   },
   {
    "duration": 350,
    "start_time": "2023-05-03T16:22:22.767Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.120Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.121Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.122Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.134Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.135Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.136Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.138Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.139Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.140Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.141Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.142Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.143Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.145Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.146Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.147Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.148Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.149Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.150Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.151Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.152Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.154Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.155Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T16:22:23.155Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
